[vocab]
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path to the training set image names
train_path = ./dataset/Flickr_8k.trainImages.txt
;path to where vocab .pkl file is to be saved
vocab_path = ./vocab.pkl
;minimum word frequency threshold
threshold = 1

[train]
;path for saving trained models
model_path = ./trained_models/
;path for vocabulary wrapper
vocab_path = ./vocab.pkl
;directory for images
image_dir = ./dataset/Flickr8k_Dataset
;path for caption file
caption_path = ./dataset/Flickr8k.token.txt
;path for train split file'
train_path = ./dataset/Flickr_8k.trainImages.txt
;path for validation split file
val_path = ./dataset/Flickr_8k.testImages.txt
;input image size for particular pretrained CNN (244/244/299)
image_size = 244
;step size for printing log info
log_step = 20
;step size for saving trained models
save_step = 1000

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512,192) 2048 for panoptic
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False

;number of epochs
num_epochs = 25
;batch size
batch_size = 64
;number of parallel workers during training
num_workers = 2
;learning rate for optimizer
learning_rate = 0.0005
;start training from scratcsh
scratch_training = True
;starting epoch (if not trained from scratch)
starting_epoch = 7 

[eval]
;path for trained encoder
encoder_path = ./trained_models/encoder-7.ckpt
;path for trained decoder
decoder_path = ./trained_models/decoder-7.ckpt
;path to vocabulary wrapper
vocab_path = ./vocab.pkl
;path to dataset images
image_dir = ./dataset/Flickr8k_Dataset
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path for val split file
val_path = ./dataset/Flickr_8k.devImages.txt
;input image size for particular pretrained CNN
image_size = 244

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512)
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False
;batch size
batch_size = 1
;number of parallel workers during training
num_workers = 0
;number of parallel beams 
beam_size = 10


;MY PROPOSALS

;Enable or disable language model rescoring during beam search
language_rescoring = False
;Enable or disable object reinforcement during beam search
object_reinforce = True


[sample]
;path for trained encoder
encoder_path = ./trained_models/encoder-20.ckpt
;path for trained decoder
decoder_path = ./trained_models/decoder-20.ckpt
;path to vocabulary wrapper
vocab_path = ./vocab.pkl
;path to dataset images
image_dir = ./dataset/Flickr8k_Dataset
;path to file that contains captions
caption_path = ./dataset/Flickr8k.token.txt
;path for val split file
val_path = ./dataset/Flickr_8k.devImages.txt
;input image size for particular pretrained CNN
image_size = 244

;cnn used for feature extraction (resnet, vgg, inception)
cnn = resnet
;dimension of extracted features (1024, 512)
encoder_size = 1024
;dimension of word embedding vectors (256,200)
embed_size = 256
;dimension of encoded image
encoded_image_size = 14
;dimension of attention layers
attention_size = 384
;dimension of lstm hidden states
hidden_size = 384
;use pre-trained embedding layer
glove = False
;batch size
batch_size = 1
;number of parallel workers during training
num_workers = 0
;number of parallel beams 
beam_size = 5
;sample image
image = ./samples/pp.jpeg


; Show attend and tell model parameters
; hidden size: 1024
; embed_size = 512
; epochs = 10
; batch_size = 100
; lr = 0.01
; optimizer adam
